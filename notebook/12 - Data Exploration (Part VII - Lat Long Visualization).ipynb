{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration (Part VII - Lat Long Visualization)\n",
    "## Review\n",
    "In the last 2 posts, we reviewed (largely using Spark and Spark SQL (very handy)) all of the interesting fields. All of them except latitude and longitude. I ended the last post puzzled about how to actually plot this many points (5 million points!). Spark didn't have anything to do this, so I had to look elsewhere. The problem here is my whole exercise is to leverage _**distributed computing**_, but at this point, my definition of distributed computing has been... exclusively _**Spark**_. So I lied a bit, but that's only because I'm stupid, lazy, and _**don't**_ want to set up some distributed graphing software and manually configure a cluster across machines.\n",
    "\n",
    "So, if _**Spark**_ won't work... what can we do? After a few google searches, I've come across a library called _**[datashader](https://github.com/bokeh/datashader)**_. Datashader claims to be able to make plots such as:\n",
    "\n",
    "<img src=\"https://github.com/bokeh/datashader/raw/master/docs/images/nyc_races.jpg\" width=\"700\">\n",
    "\n",
    "Lo and behold... that's pretty much what I'm looking for... A map of NYC! In the map above, the folks at datashader have mapped out the most prominent races according to the NYC census data. I feel like that's pretty much what I want, except the most prominent race becomes the prominent type of crime, or by the most prominent seriousness of a crime (violation, misdemeanor, felony).\n",
    "\n",
    "Man... now I feel like a super basic data geek who thinks he's cool because he's working with NYC data...\n",
    "\n",
    "<img src=\"https://booktrib.com/wp-content/uploads/2015/10/basic-bitch.jpg\" width=\"400\">\n",
    "\n",
    "The worst part? It took me 12 posts to realize it. Oh well, onward we move.\n",
    "\n",
    "## Datashader\n",
    "Here's a tutorial of datashader that honestly outputs some breathtaking visualizations.\n",
    "\n",
    "[![IMAGE ALT TEXT](http://img.youtube.com/vi/fB3cUrwxMVY/0.jpg)](http://www.youtube.com/watch?v=fB3cUrwxMVY \"Video Title\")\n",
    "\n",
    "Watching this video actually gives an interesting perspective on big data plotting as well. They approached datashader with a big data motivation, but not in the compute sense... more in the art of visualization sense. Their reasoning is that, simply plotting like a million points in a small area (a common example they use is thinking of how many data points is packed into each pixel on screen) will yield perception and accuracy problems.\n",
    "\n",
    "[This post by the folks at Continuum](https://anaconda.org/jbednar/plotting_pitfalls/notebook?version=2016.11.11.1140) (who created datashader) shows some of the pitfalls of plotting a ton of data. Their argument is that, if any of these 6 pitfalls occur, the visualization may _**literally be lying to you**_.\n",
    "\n",
    "The first one they talk about is _**overplotting**_. This is something I run into all the time and have used the alpha / opacity plotting parameter to solve in the past. Overplotting is when we have 2 classes identified by different colors plotted on the same chart. Let's say one group is plotted with blue, and the other is plotting in red:\n",
    "\n",
    "![](https://s3.ca-central-1.amazonaws.com/2017edmfasatb/nypd_complaints/images/29_overplotting.png)\n",
    "\n",
    "We can see, depending on the order in which we plot the points actually matter. If we plot red first, then blue, we get image _**C**_ which masks many of the red points... we simply don't know if the red is there because we cannot see the bottom layer of the plot! Image _**D**_ is just the opposite - we can infer that there are blue points, and we may have already been biased looking at these sets of photos because we already know the true state of the data, but if we were looking at D for the first time we may not have been able to tell if the blue dots really exist!\n",
    "\n",
    "This is when I'd play around with the alpha, or opacity of the dots to make the visualization a bit more truthful:\n",
    "\n",
    "![](https://s3.ca-central-1.amazonaws.com/2017edmfasatb/nypd_complaints/images/30_oversaturation.png)\n",
    "\n",
    "Even here, we see that it's not perfect as there still is a difference between C and D. The datashader documentation then goes on to state that having to tweak the opacity and the dot sizes (see below with same opacity, but smaller dots)\n",
    "\n",
    "![](https://s3.ca-central-1.amazonaws.com/2017edmfasatb/nypd_complaints/images/31_oversaturation_small_dots.png)\n",
    "\n",
    "makes the visualization process much slower and takes away the focus from what we're actually trying to do! It goes on to describe 4 more pitfalls that could occur when visualization the data, and continues to make the point that\n",
    "\n",
    "> _**For big data, you don't know when the viz is lying**_\n",
    "\n",
    "This comes from datashader's definition of big data that is\n",
    "\n",
    "> _**Data is big when you can't make any inferences from any single point of data**_\n",
    "\n",
    "This implies that the data is so granular (a single incident at a single lat long) that you're not meant to be able to infer any overall conclusions from a single data point, and going through every single point is an inefficient (and in all likelihood impossible) task because of pure volume. In a case like this, _**all you can rely on is the visualization**_, and if the visualization is incorrect, you don't have any QA tools to notice, so it's best to use the right theory from the get go.\n",
    "\n",
    "When I tried to build a heatmap from the [Edmonton Property Assessment data](https://strikingmoose.com/2017/07/31/building-a-regression-model-k-nn/), the method I tried was to build a regression model that predicts an assessment value for each lat long value / range. In K-NN, we can infer lat / longs which do not have a property assessment tied to them by taking a look at those around them. In essence, we build a gradient across the lats and longs to communicate the predicted assessment value. After doing that, my visualization consisted of a set of predictions on _**a grid of inputs across edmonton**_ to ensure I have every area covered.\n",
    "\n",
    "In this example, what I'd like to visualize is the _**volume of incidents**_, which I have inherently in the data, so I don't have to do anything fancy with predictive models. However, I still face all the problems that datashader has laid out. What datashader does is similar to what I had done in the [Edmonton Property Assessment](https://strikingmoose.com/2017/07/31/building-a-regression-model-k-nn/) post in that\n",
    "1. It represents each pixel of the screen is represented by a value, not solely represented by the data points contributing to that pixel\n",
    "2. \\#1 is true because the value is represented by an _**overall model**_ that has the context of _**the entire dataset**_, not just the pixel in question\n",
    "\n",
    "In datashader's example, if we set an alpha to 0.1, we are indicating that 10 points lying on top of each other will achieve _**full saturation**_. If, in our data, we only have points that are either not overlapping (singular points), or they overlap by 50 points at a time, it would be very difficult to create a plot that can show off this contrast well because anything over 10 points at a time will achieve full saturation! Anything between 10 and 50 points overlapping will look the same to the user. That's what happens when we don't generalize our data to some type of heatmap or model. This is where datashader's real advantage comes in, because datashader allows you to easily map your own model without having to go through the trouble that I went through in the [Edmonton Property Assessment](https://strikingmoose.com/2017/07/31/building-a-regression-model-k-nn/) project. Granted, I don't know if datashader can perform regression, but it's got a lot of great gradients (e.g. using log instead of linear) for our specific purpose, analying volumes of points in a region where each point is weighted the same!\n",
    "\n",
    "## But Wait...\n",
    "But wait... what happened to the whole thing about not being able to use Spark anymore? I thought we were trying to leverage distributed computing for this project? I agree, I am being a bit lazy here in dropping distributed computing altogether in this plot, but in the datashader video above, the guy plots _**ONE BILLION POINTS**_, and he does it on his Mac which I assume has no more than 32GB RAM (I'm probably wrong). If I think about it objectively, the inputs of a map are simply latitude and longitudes. The dataset is 1.3 GB, but the lats and longs probably only account for like 1/50th of the entire file size! Lat / longs are bounded by however many significant digits of the lat / long itself. A latitude like 53.631611 will always only take 9 bytes to represent, whereas a text description field is often much longer and variable. Given that there's about 35 rows of data in our parquet dataframe, lat / longs accounting for 1/50th of the file size isn't so farfetched to me! That brings down the file size to 30 MB. Let's say our own laptop had 32 GB memory, we could handle over _**1 TB**_ of just latitude and longitude data in memory.\n",
    "\n",
    "There are different solutions for everything, and perhaps this one is the path of least resistance for mapping functionality!\n",
    "\n",
    "## Back To Datashader\n",
    "Let's try to import the dataset into Jupyter. I've found this package pyarrow which can apparently read parquet files into a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system(\"sudo pip install pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowIOError",
     "evalue": "Failed to open local file: s3://2017edmfasatb/nypd_complaints/data/df_filtered.parquet",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowIOError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9dbb05df7db3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyarrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"s3://2017edmfasatb/nypd_complaints/data/df_filtered.parquet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib64/python2.7/site-packages/pyarrow/parquet.pyc\u001b[0m in \u001b[0;36mread_table\u001b[0;34m(source, columns, nthreads, metadata, use_pandas_metadata)\u001b[0m\n\u001b[1;32m    722\u001b[0m                                    metadata=metadata)\n\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m     \u001b[0mpf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParquetFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m     return pf.read(columns=columns, nthreads=nthreads,\n\u001b[1;32m    726\u001b[0m                    use_pandas_metadata=use_pandas_metadata)\n",
      "\u001b[0;32m/usr/local/lib64/python2.7/site-packages/pyarrow/parquet.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, source, metadata, common_metadata)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommon_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParquetReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommon_metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python2.7/site-packages/pyarrow/_parquet.pyx\u001b[0m in \u001b[0;36mpyarrow._parquet.ParquetReader.open (/arrow/python/build/temp.linux-x86_64-2.7/_parquet.cxx:8115)\u001b[0;34m()\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m         \u001b[0mget_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m&\u001b[0m\u001b[0mrd_handle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mnogil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             check_status(OpenFile(rd_handle, self.allocator, properties,\n",
      "\u001b[0;32mpyarrow/io.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.get_reader (/arrow/python/build/temp.linux-x86_64-2.7/lib.cxx:46747)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpyarrow/io.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.memory_map (/arrow/python/build/temp.linux-x86_64-2.7/lib.cxx:43943)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpyarrow/io.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.MemoryMappedFile._open (/arrow/python/build/temp.linux-x86_64-2.7/lib.cxx:43722)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpyarrow/error.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.check_status (/arrow/python/build/temp.linux-x86_64-2.7/lib.cxx:7495)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowIOError\u001b[0m: Failed to open local file: s3://2017edmfasatb/nypd_complaints/data/df_filtered.parquet"
     ]
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "pq.read_table(\"s3://2017edmfasatb/nypd_complaints/data/df_filtered.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
